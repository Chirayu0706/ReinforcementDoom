{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64fbcf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizdoom import *\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "!cd github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e04ec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "game = DoomGame()\n",
    "game.load_config('github/VizDoom/scenarios/basic.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4a10398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actions = np.identity(3,dtype = np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fd0aaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b2eb17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "game.new_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1407f9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PyCapsule.is_episode_finished of <vizdoom.vizdoom.DoomGame object at 0x000001EDF371D230>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.is_episode_finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92bcf0ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.make_action(random.choice(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24f84057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: 99.0\n",
      "Result: 83.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: 97.0\n",
      "reward: -1.0\n",
      "Result: -96.0\n",
      "reward: -4.0\n",
      "reward: 99.0\n",
      "Result: 95.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: 99.0\n",
      "Result: 83.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: 97.0\n",
      "Result: 64.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: 99.0\n",
      "Result: 79.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: 99.0\n",
      "Result: -45.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "Result: -370.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "Result: -370.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: 99.0\n",
      "Result: 91.0\n"
     ]
    }
   ],
   "source": [
    "# Loop through episodes \n",
    "episodes = 10 \n",
    "for episode in range(episodes): \n",
    "    # Create a new episode or game \n",
    "    game.new_episode()\n",
    "    # Check the game isn't done \n",
    "    while not game.is_episode_finished(): \n",
    "        # Get the game state \n",
    "        state = game.get_state()\n",
    "        # Get the game image from game state\n",
    "        img = state.screen_buffer\n",
    "        # Get the game variables - ammo from state\n",
    "        info = state.game_variables\n",
    "        # Take an action\n",
    "        reward = game.make_action(random.choice(actions),4)#4 over here is for frame buffer we skip next 4 frame after actions to see the reward of the action\n",
    "        # Print rewward \n",
    "        print('reward:', reward) \n",
    "        time.sleep(0.02)\n",
    "    print('Result:', game.get_total_reward())\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cd0bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d964abe0",
   "metadata": {},
   "source": [
    "# Converting it to OpenAi Gym "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b368750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gym) (1.20.3)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gym) (1.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c196a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de994c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vizdoom OpenAI Gym Environment\n",
    "class VizDoomGym(Env): \n",
    "    # Function that is called when we start the env\n",
    "    def __init__(self, render=False): \n",
    "        # Inherit from Env\n",
    "        super().__init__()\n",
    "        # Setup the game \n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config('github/VizDoom/scenarios/basic.cfg')\n",
    "        \n",
    "        # Render frame logic\n",
    "        if render == False: \n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "        \n",
    "        # Start the game \n",
    "        self.game.init()\n",
    "        \n",
    "        # Create the action space and observation space\n",
    "        self.observation_space = Box(low=0, high=255, shape=(100,160,1), dtype=np.uint8) \n",
    "        self.action_space = Discrete(3)\n",
    "        \n",
    "    # This is how we take a step in the environment\n",
    "    def step(self, action):\n",
    "        # Specify action and take step \n",
    "        actions = np.identity(3)\n",
    "        reward = self.game.make_action(actions[action], 4) \n",
    "        \n",
    "        # Get all the other stuff we need to retun \n",
    "        if self.game.get_state(): \n",
    "            state = self.game.get_state().screen_buffer\n",
    "            state = self.grayscale(state)\n",
    "            ammo = self.game.get_state().game_variables[0]\n",
    "            info = ammo\n",
    "        else: \n",
    "            state = np.zeros(self.observation_space.shape)\n",
    "            info = 0 \n",
    "        \n",
    "        info = {\"info\":info}\n",
    "        done = self.game.is_episode_finished()\n",
    "        \n",
    "        return state, reward, done, info \n",
    "    \n",
    "    # Define how to render the game or environment \n",
    "    def render(): \n",
    "        pass\n",
    "    \n",
    "    # What happens when we start a new game \n",
    "    def reset(self): \n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        return self.grayscale(state)\n",
    "    \n",
    "    # Grayscale the game frame and resize it \n",
    "    def grayscale(self, observation):\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (160,100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100,160,1))\n",
    "        return state\n",
    "    \n",
    "    # Call to close down the game\n",
    "    def close(self): \n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42fa38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = VizDoomGym(render=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "738e5868",
   "metadata": {},
   "outputs": [],
   "source": [
    "######When You Are making your own env check if the env you coded is valid by using this#####\n",
    "from stable_baselines3.common import env_checker\n",
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df89535e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[71],\n",
       "         [76],\n",
       "         [72],\n",
       "         ...,\n",
       "         [75],\n",
       "         [71],\n",
       "         [72]],\n",
       " \n",
       "        [[58],\n",
       "         [35],\n",
       "         [33],\n",
       "         ...,\n",
       "         [34],\n",
       "         [33],\n",
       "         [35]],\n",
       " \n",
       "        [[67],\n",
       "         [74],\n",
       "         [55],\n",
       "         ...,\n",
       "         [27],\n",
       "         [27],\n",
       "         [27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[75],\n",
       "         [63],\n",
       "         [62],\n",
       "         ...,\n",
       "         [44],\n",
       "         [71],\n",
       "         [60]],\n",
       " \n",
       "        [[15],\n",
       "         [48],\n",
       "         [47],\n",
       "         ...,\n",
       "         [49],\n",
       "         [69],\n",
       "         [47]],\n",
       " \n",
       "        [[22],\n",
       "         [14],\n",
       "         [26],\n",
       "         ...,\n",
       "         [57],\n",
       "         [37],\n",
       "         [39]]], dtype=uint8),\n",
       " -9.0,\n",
       " False,\n",
       " {'info': 48.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1408992b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a1bc4",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f24cc145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d33db300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cb458fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_basic'\n",
    "LOG_DIR = './logs/log_basic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51819d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=50000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae95a6",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5703c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "299b0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non rendered environment\n",
    "env = VizDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6632451",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO('CnnPolicy', env, verbose=1, learning_rate=0.0001, n_steps=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "d25fb477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.7     |\n",
      "|    ep_rew_mean     | -78      |\n",
      "| time/              |          |\n",
      "|    fps             | 32       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.3        |\n",
      "|    ep_rew_mean          | -94.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 301         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009303957 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.000115   |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | 0.000806    |\n",
      "|    value_loss           | 2.52e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.6        |\n",
      "|    ep_rew_mean          | -62.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 11          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 539         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008349172 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.0441      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.4e+03     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.000699   |\n",
      "|    value_loss           | 3.02e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23          |\n",
      "|    ep_rew_mean          | -21.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 10          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 802         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007759258 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    value_loss           | 3.1e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | -66.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 9           |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 1068        |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029067058 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.26e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.000119   |\n",
      "|    value_loss           | 4.07e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 21.8        |\n",
      "|    ep_rew_mean          | -20.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 9           |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 1326        |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017338097 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | 0.000206    |\n",
      "|    value_loss           | 3.06e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.8        |\n",
      "|    ep_rew_mean          | 26.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 9           |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 1590        |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018813323 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | 0.00614     |\n",
      "|    value_loss           | 3.05e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.4        |\n",
      "|    ep_rew_mean          | 12.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 8           |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 1852        |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027355235 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.962      |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2e+03       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00222    |\n",
      "|    value_loss           | 3.99e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.9        |\n",
      "|    ep_rew_mean          | 5.92        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 8           |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 2125        |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028653627 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.935      |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.84e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | 0.00697     |\n",
      "|    value_loss           | 3.77e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.1        |\n",
      "|    ep_rew_mean          | 38.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 8           |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 2402        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021923369 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.887      |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.82e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | 0.00139     |\n",
      "|    value_loss           | 3.07e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18          |\n",
      "|    ep_rew_mean          | 12.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 8           |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 2668        |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020608021 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.886      |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.4e+03     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | 0.00458     |\n",
      "|    value_loss           | 2.78e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.7       |\n",
      "|    ep_rew_mean          | 53         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 8          |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 2937       |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03458724 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.811     |\n",
      "|    explained_variance   | 0.542      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.15e+03   |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | 0.0145     |\n",
      "|    value_loss           | 2.6e+03    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 6.07       |\n",
      "|    ep_rew_mean          | 77         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 8          |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 3221       |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06404831 |\n",
      "|    clip_fraction        | 0.368      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.763     |\n",
      "|    explained_variance   | 0.761      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.07e+03   |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.00417   |\n",
      "|    value_loss           | 1.67e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 11.6       |\n",
      "|    ep_rew_mean          | 51.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 8          |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 3496       |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07579288 |\n",
      "|    clip_fraction        | 0.552      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.805     |\n",
      "|    explained_variance   | 0.678      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 423        |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | 0.0465     |\n",
      "|    value_loss           | 892        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.8        |\n",
      "|    ep_rew_mean          | 60.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 8          |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 3770       |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03354678 |\n",
      "|    clip_fraction        | 0.423      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.785     |\n",
      "|    explained_variance   | 0.535      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 430        |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | 0.0075     |\n",
      "|    value_loss           | 903        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.38        |\n",
      "|    ep_rew_mean          | 65          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 8           |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 4046        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043131426 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.774      |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 465         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00704    |\n",
      "|    value_loss           | 966         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.37        |\n",
      "|    ep_rew_mean          | 71.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 8           |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 4332        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045766894 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.675      |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 285         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.00551     |\n",
      "|    value_loss           | 698         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.76        |\n",
      "|    ep_rew_mean          | 78.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 4616        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050357085 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.662      |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 319         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    value_loss           | 397         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 7.25       |\n",
      "|    ep_rew_mean          | 72.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 7          |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 4898       |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07758559 |\n",
      "|    clip_fraction        | 0.415      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.657     |\n",
      "|    explained_variance   | 0.698      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 78.9       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | 0.072      |\n",
      "|    value_loss           | 351        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.55        |\n",
      "|    ep_rew_mean          | 75.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 5183        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051266637 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.558      |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 313         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    value_loss           | 917         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.57        |\n",
      "|    ep_rew_mean          | 84.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 5478        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.067822464 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.477      |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 334         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.96        |\n",
      "|    ep_rew_mean          | 82.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 5769        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026421005 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.451      |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 52.8        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | 0.0252      |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.22        |\n",
      "|    ep_rew_mean          | 85.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 6067        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044601794 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 57.4        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | 0.00348     |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.19        |\n",
      "|    ep_rew_mean          | 85.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 6371        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018453632 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.0323      |\n",
      "|    value_loss           | 55.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.3        |\n",
      "|    ep_rew_mean          | 85.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 7          |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 6675       |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06647465 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.258     |\n",
      "|    explained_variance   | 0.653      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 27.4       |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | 0.0032     |\n",
      "|    value_loss           | 85.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.33        |\n",
      "|    ep_rew_mean          | 79.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 7011        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030323286 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.228      |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.0144      |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.52        |\n",
      "|    ep_rew_mean          | 79.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 7412        |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025940262 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.203      |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 81.6        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 0.00691     |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.98        |\n",
      "|    ep_rew_mean          | 86.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 7837        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062136024 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.156      |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00618    |\n",
      "|    value_loss           | 247         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.29       |\n",
      "|    ep_rew_mean          | 85.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 7          |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 8240       |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03549269 |\n",
      "|    clip_fraction        | 0.096      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.158     |\n",
      "|    explained_variance   | 0.902      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 157        |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | 0.0045     |\n",
      "|    value_loss           | 100        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.2         |\n",
      "|    ep_rew_mean          | 85.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 8686        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031099787 |\n",
      "|    clip_fraction        | 0.0913      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.151      |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 54.1        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | 0.0278      |\n",
      "|    value_loss           | 57.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.6        |\n",
      "|    ep_rew_mean          | 88.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 7          |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 9044       |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02658273 |\n",
      "|    clip_fraction        | 0.0888     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.134     |\n",
      "|    explained_variance   | 0.674      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 19.8       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | 0.00348    |\n",
      "|    value_loss           | 65.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.23        |\n",
      "|    ep_rew_mean          | 86          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 9420        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028546419 |\n",
      "|    clip_fraction        | 0.0771      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.153      |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3           |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.0478      |\n",
      "|    value_loss           | 21.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.37      |\n",
      "|    ep_rew_mean          | 85.2      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 6         |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 9791      |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0153779 |\n",
      "|    clip_fraction        | 0.0522    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.118    |\n",
      "|    explained_variance   | 0.823     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 18        |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | 0.0155    |\n",
      "|    value_loss           | 25.5      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.4         |\n",
      "|    ep_rew_mean          | 85          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 10142       |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046061203 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.146      |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.27        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | 0.0253      |\n",
      "|    value_loss           | 16.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 3.35      |\n",
      "|    ep_rew_mean          | 89.5      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 6         |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 10509     |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0773948 |\n",
      "|    clip_fraction        | 0.0658    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.14     |\n",
      "|    explained_variance   | 0.646     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 19.5      |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | 0.00499   |\n",
      "|    value_loss           | 63.1      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.43        |\n",
      "|    ep_rew_mean          | 85.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 10859       |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022086034 |\n",
      "|    clip_fraction        | 0.0841      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.111      |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.03        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00107    |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.4         |\n",
      "|    ep_rew_mean          | 85          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 11223       |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014485603 |\n",
      "|    clip_fraction        | 0.0616      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.104      |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.47        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | 0.000821    |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.85        |\n",
      "|    ep_rew_mean          | 87.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 11593       |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030764442 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.106      |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | 0.00772     |\n",
      "|    value_loss           | 56.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.05        |\n",
      "|    ep_rew_mean          | 86.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 12001       |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021179691 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0899     |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 11.8        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.0184      |\n",
      "|    value_loss           | 25.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.91        |\n",
      "|    ep_rew_mean          | 87.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 12324       |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024446942 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0935     |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 9.31        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.0113      |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9988/2886439321.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    297\u001b[0m     ) -> \"PPO\":\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m         return super(PPO, self).learn(\n\u001b[0m\u001b[0;32m    300\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[0mcontinue_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[1;31m# Convert to pytorch tensor or to TensorDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                 \u001b[0mobs_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs_as_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                 \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \"\"\"\n\u001b[0;32m    587\u001b[0m         \u001b[1;31m# Preprocess the observation if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mlatent_pi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_vf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;31m# Evaluate the values for the given observations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No features extractor was set\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mpreprocessed_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize_images\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_obs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_constructor_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\torch_layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, observations)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    441\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 443\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    444\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8134e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_path = os.path.join('Training', 'Saved Models', 'PPO_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bcfba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "7afb9917",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model #Just deleted the model not the saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0093103",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(PPO_path, env=env) #reloaded the model fron the saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ffda410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-300.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "env = VizDoomGym(render=True) \n",
    "mean_reward = evaluate_policy(model,env,n_eval_episodes=10)\n",
    "print(mean_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15f1cbf2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12752/3317976099.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'obs' is not defined"
     ]
    }
   ],
   "source": [
    "model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e95133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2138637",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for episode in range(100): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        # time.sleep(0.20)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode,total_reward))\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71359ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
